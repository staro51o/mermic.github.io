# Except of [01_intro.ipynb_for_1.pdf](pdf/01_intro.ipynb_for_1.pdf)

![](/images/01_code_01.png "STEP.1")

from fastai.vision.all import*

The first line imports all of the fastai.vision library.

This gives us all of the functions and classes we will need to create a wide variety of computer vision models.

path = untar_data(URLs.PETS)/'images'

The second line downloads a standard dataset from the fast.ai datasets collection (if not previously downloaded) to your server, 
extracts it (if not previously extracted location.

def is_cat(x): return x[0].isupper()

In the third line we define a function, is_cat, which labels cats based on a filename rule provided by the dataset creators.

We use that function in the fourth line, which tells fastai what kind of dataset we have and how it is structured.

dls = ImageDataLoaders.from_name_func(
  path, get_image_files(path), valid_pct=0.2, seed=42, 
  label_func=is_cat, item_tfms=Resize(224))

There are various different classes for different kinds of deep learning datasets and problems—here we're using ImageDataLoaders. 
The first part of the class name will generally be the type of data you have, such as image, or text.

The other important piece of information that we have to tell fastai is how to get the labels from the dataset. 
Computer vision datasets are normally structured in such a way that the label for an image is part of the filename, or path—most commonly the parent folder name. 
fastai comes with a number of standardized labeling methods, and ways to write your own. Here we're telling fastai to use the is_cat function we just defined.

Finally, we define the Transforms that we need. A Transform contains code that is applied automatically during
training; fastai includes many predefined Transforms, and adding new ones is as simple as creating a Python
function. There are two kinds: item_tfms are applied to each item (in this case, each item is resized to a 224-pixel square), 
while batch_tfms are applied to a batch of items at a time using the GPU, so they're particularly fast.

The filenames start with an uppercase letter if the image is a cat, and a
lowercase letter otherwise. We have to tell fastai how to get labels from the filenames, which we do by
calling from_name_func (which means that labels can be extracted using a function applied to the filename), and
passing is_cat, which returns x[0].isupper(), which evaluates to True if the first letter is uppercase (i.e., it's a cat).

The most important parameter to mention here is valid_pct=0.2. This tells fastai to hold out 20% of the data
and not use it for training the model at all. This 20% of the data is called the validation set; the remaining 80% is
called the training set. The validation set is used to measure the accuracy of the model. By default, the 20% that is held out is selected randomly. The parameter seed=42 sets the random seed to the same value every time we run
this code, which means we get the same validation set every time we run it—this way, if we change our model and
retrain it, we know that any differences are due to the changes to the model, not due to having a different random
validation set.

fastai will always show you your model's accuracy using only the validation set, never the training set. This is absolutely critical, 
because if you train a large enough model for a long enough time, it will eventually memorize the label of every item in your dataset! 
The result will not actually be a useful model, because what we care about is how well our model works on previously unseen images. 
That is always our goal when creating a model: for it to be useful on data that the model only sees in the future, after it has been trained.

Even when your model has not fully memorized all your data, earlier on in training it may have memorized certain
parts of it. As a result, the longer you train for, the better your accuracy will get on the training set; the validation
set accuracy will also improve for a while, but eventually it will start getting worse as the model starts to memorize
the training set, rather than finding generalizable underlying patterns in the data. When this happens, we say that
the model is overfitting.

learn = vision_learner(dls, resnet34, metrics=error_rate)

The fifth line of the code training our image recognizer tells fastai to create a convolutional neural network (CNN) and specifies 
what architecture to use (i.e. what kind of model to create), what data we want to train it on, and what metric to use.

The 34 in resnet34 refers to the number of layers in this variant of the architecture (other options are 18, 50, 101, and 152). 
Models using architectures with more layers take longer to train, 
and are more prone to overfitting (i.e. you can't train them for as many epochs before the accuracy on the validation set starts getting worse). 
On the other hand, when using more data, they can be quite a bit more accurate.

A metric is a function that measures the quality of the model's predictions using the validation
set, and will be printed at the end of each epoch. In this case, we're using error_rate, which is a function provided
by fastai that does just what it says: tells you what percentage of images in the validation set are being classified incorrectly.

vision_learner also has a parameter pretrained, which defaults to True 
(so it's used in this case, even though we haven't specified it), 
which sets the weights in your model to values that have already been trained by experts to
recognize a thousand different categories across 1.3 million photos (using the famous ImageNet dataset). 
A model that has weights that have already been trained on some other dataset is called a pretrained model. 
You should nearly always use a pretrained model, because it means that your model, before you've even shown it any of your data, is already very capable.

When using a pretrained model, vision_learner will remove the last layer, since that is always specifically
customized to the original training task (i.e. ImageNet dataset classification), and replace it with one or more new
layers with randomized weights, of an appropriate size for the dataset you are working with. This last part of the model is known as the head.

learn.fine_tune(1)

The sixth line of our code tells fastai how to fit the model.

